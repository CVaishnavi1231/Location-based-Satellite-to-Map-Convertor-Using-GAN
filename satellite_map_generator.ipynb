{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SRM3o5P4VP9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/sat_to_map/maps.zip"
      ],
      "metadata": {
        "id": "FkPuFLpoHWgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import os\n",
        "from numpy import asarray, load\n",
        "from numpy import vstack\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from numpy import savez_compressed\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import glob\n",
        "import imageio\n",
        "from numpy.random import randint\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from geopy.geocoders import Nominatim\n",
        "import urllib.request\n",
        "import math\n",
        "import cv2"
      ],
      "metadata": {
        "id": "5xHv0r4_MfIf"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "89xswQXzMfw1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Map Dataset"
      ],
      "metadata": {
        "id": "_SL_rultMkkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(path, size=(256,512)):\n",
        "\tsrc_list, tar_list = list(), list()\n",
        "\tfor filename in listdir(path):\n",
        "\t\tif filename == '.DS_Store':\n",
        "\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tfor f in listdir(path + filename):\n",
        "\t\t\t\ttemp = path + filename + '/' + f\n",
        "\t\t\t\tpixels = load_img(temp, target_size=size)\n",
        "\t\t\t\tpixels = img_to_array(pixels)\n",
        "\t\t\t\tsat_img, map_img = pixels[:, :256], pixels[:, 256:]\n",
        "\t\t\t\tsrc_list.append(sat_img)\n",
        "\t\t\t\ttar_list.append(map_img)\n",
        "\treturn [asarray(src_list), asarray(tar_list)]\n",
        "\n",
        "path = '/content/maps/train/'\n",
        "[src_images, tar_images] = load_images(path)\n",
        "print('Loaded: ', src_images.shape, tar_images.shape)\n",
        "\n",
        "\n",
        "n_samples = 3\n",
        "for i in range(n_samples):\n",
        "\tpyplot.subplot(2, n_samples, 1 + i)\n",
        "\tpyplot.axis('off')\n",
        "\tpyplot.imshow(src_images[i].astype('uint8'))\n",
        "\n",
        "for i in range(n_samples):\n",
        "\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\tpyplot.axis('off')\n",
        "\tpyplot.imshow(tar_images[i].astype('uint8'))\n",
        "pyplot.show()\n",
        "\n",
        "\n",
        "data = [src_images, tar_images]\n",
        "\n",
        "def preprocess_data(data):\n",
        "\tX1, X2 = data[0], data[1]\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        "\n",
        "dataset = preprocess_data(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "zWJJxxCF6rgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Definition"
      ],
      "metadata": {
        "id": "sscxe-ekM2X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_discriminator(image_shape):\n",
        "    \n",
        "\tinit = RandomNormal(stddev=0.02) #As described in the original paper\n",
        "    \n",
        "\tin_src_image = Input(shape=image_shape) \n",
        "\tin_target_image = Input(shape=image_shape)  \n",
        "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
        "    \n",
        "\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\tpatch_out = Activation('sigmoid')(d)\n",
        "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
        "    \n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\tif batchnorm:\n",
        "\t\tg = BatchNormalization()(g, training=True)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\treturn g\n",
        "\n",
        "\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\tg = BatchNormalization()(g, training=True)\n",
        "\tif dropout:\n",
        "\t\tg = Dropout(0.5)(g, training=True)\n",
        "\tg = Concatenate()([g, skip_in])\n",
        "\tg = Activation('relu')(g)\n",
        "\treturn g\n",
        "\n",
        "\n",
        "def define_generator(image_shape=(256,256,3)):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
        "\te2 = define_encoder_block(e1, 128)\n",
        "\te3 = define_encoder_block(e2, 256)\n",
        "\te4 = define_encoder_block(e3, 512)\n",
        "\te5 = define_encoder_block(e4, 512)\n",
        "\te6 = define_encoder_block(e5, 512)\n",
        "\te7 = define_encoder_block(e6, 512)\n",
        " \n",
        "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
        "\tb = Activation('relu')(b)\n",
        "\n",
        "\td1 = decoder_block(b, e7, 512)\n",
        "\td2 = decoder_block(d1, e6, 512)\n",
        "\td3 = decoder_block(d2, e5, 512)\n",
        "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
        "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
        "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "\n",
        "\tg = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)  \n",
        "\tout_image = Activation('tanh')(g)  \n",
        "\tmodel = Model(in_image, out_image)\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def define_gan(g_model, d_model, image_shape):\n",
        "\tfor layer in d_model.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False       \n",
        "            \n",
        "\tin_src = Input(shape=image_shape)\n",
        "\tgen_out = g_model(in_src)\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        "\tmodel = Model(in_src, [dis_out, gen_out])\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    \n",
        "\tmodel.compile(loss=['binary_crossentropy', 'mae'], \n",
        "               optimizer=opt, loss_weights=[1,100])\n",
        "\treturn model\n",
        "\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\ttrainA, trainB = dataset\n",
        "\tix = randint(0, trainA.shape[0], n_samples)\n",
        "\tX1, X2 = trainA[ix], trainB[ix]\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn [X1, X2], y\n",
        "\n",
        "\n",
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\tX = g_model.predict(samples)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "\n",
        "def summarize_performance(step, g_model, dataset, n_samples=3):\n",
        "\t# select a sample of input images\n",
        "\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
        "\t# generate a batch of fake samples\n",
        "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_realA = (X_realA + 1) / 2.0\n",
        "\tX_realB = (X_realB + 1) / 2.0\n",
        "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
        "\t# plot real source images\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_realA[i])\n",
        "\t# plot generated target image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_fakeB[i])\n",
        "\t# plot real target image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_realB[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'plot_%06d.png' % (step+1)\n",
        "\tplt.savefig(filename1)\n",
        "\tplt.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = '/content/drive/MyDrive/sat_to_map/model_%06d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        "\n",
        "# train pix2pix models\n",
        "def train(d_model, g_model, gan_model, dataset, n_epochs=500, n_batch=1):\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\t# update discriminator for real samples\n",
        "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\t# update discriminator for generated samples\n",
        "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\t# update the generator\n",
        "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "\t\t# summarize model performance\n",
        "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, dataset)\n"
      ],
      "metadata": {
        "id": "B4k1ZuT6UIjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "-25tHyZ0QuTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape = src_images.shape[1:]\n",
        "d_model = define_discriminator(image_shape)\n",
        "g_model = define_generator(image_shape)\n",
        "gan_model = define_gan(g_model, d_model, image_shape)\n",
        "\n",
        "\n",
        "train(d_model, g_model, gan_model, dataset, n_epochs=500, n_batch=1) "
      ],
      "metadata": {
        "id": "7R0kP5XdMyEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "ZVx8ANYYGr9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lat_long(city,country):\n",
        "  geolocator = Nominatim(user_agent=\"my_user_agent\")\n",
        "  loc = geolocator.geocode(city+','+ country)\n",
        "  return loc.latitude,loc.longitude"
      ],
      "metadata": {
        "id": "OtmhhBoNTmLp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROADMAP = \"v\"\n",
        "TERRAIN = \"p\"\n",
        "ALTERED_ROADMAP = \"r\"\n",
        "SATELLITE = \"s\"\n",
        "TERRAIN_ONLY = \"t\"\n",
        "HYBRID = \"y\"\n",
        "\n",
        "\n",
        "def GoogleMapDownloader(latitude,longitude):\n",
        "    lat = latitude\n",
        "    lng = longitude\n",
        "    zoom = 12\n",
        "    layer = SATELLITE\n",
        "\n",
        "    tile_size = 256\n",
        "    numTiles = 1 << zoom\n",
        "    point_x = (tile_size / 2 + lng * tile_size / 360.0) * numTiles // tile_size\n",
        "    sin_y = math.sin(lat * (math.pi / 180.0))\n",
        "    point_y = ((tile_size / 2) + 0.5 * math.log((1 + sin_y) / (1 - sin_y)) * -(\n",
        "    tile_size / (2 * math.pi))) * numTiles // tile_size\n",
        "\n",
        "    start_x = int(point_x)\n",
        "    start_y = int(point_y)\n",
        "\n",
        "    tile_width = tile_height = 4\n",
        "\n",
        "    width, height = 128 * tile_width, 128 * tile_height\n",
        "\n",
        "    map_img = Image.new('RGB', (width, height))\n",
        "\n",
        "    for x in range(0, tile_width):\n",
        "      for y in range(0, tile_height):\n",
        "          url = f'https://mt0.google.com/vt?lyrs={layer}&x=' + str(start_x + x) + '&y=' + str(start_y + y) + '&z=' + str(\n",
        "                    zoom)\n",
        "\n",
        "          current_tile = str(x) + '-' + str(y)\n",
        "          urllib.request.urlretrieve(url, current_tile)\n",
        "\n",
        "          im = Image.open(current_tile)\n",
        "          map_img.paste(im, (x * 256, y * 256))\n",
        "\n",
        "          os.remove(current_tile)\n",
        "          \n",
        "\n",
        "    return map_img"
      ],
      "metadata": {
        "id": "nK6STWfriW1A"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interval_mapping(image, from_min, from_max, to_min, to_max):\n",
        "    from_range = from_max - from_min\n",
        "    to_range = to_max - to_min\n",
        "    scaled = np.array((image - from_min) / float(from_range), dtype=float)\n",
        "    return to_min + (scaled * to_range)"
      ],
      "metadata": {
        "id": "sh8iYG6mRizF"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city = input('Enter the city/place name: ')\n",
        "country = input('Enter the country/city name: ')\n",
        "lat,lon = get_lat_long(city,country)\n",
        "gmd = GoogleMapDownloader(lat, lon)\n",
        "im_crop = gmd.crop((128, 128, 384, 384))\n",
        "img = np.asarray(im_crop)\n",
        "\n",
        "print(\"The satellite image of the place is:\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "model = load_model('/content/model_471280.h5')\n",
        "img = np.reshape(img, (1,256,256,3))\n",
        "gen_image = model.predict(img)\n",
        "\n",
        "print(\"The output map image generated is \")\n",
        "output_image =interval_mapping(gen_image, 0.0, 1.0, 0, 255).astype('uint8')\n",
        "\n",
        "cv2_imshow(output_image[0,:,:,:])"
      ],
      "metadata": {
        "id": "TmMUwGBmVwGc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}